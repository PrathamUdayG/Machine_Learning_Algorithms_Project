{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1: Load & basic cleaning**"
      ],
      "metadata": {
        "id": "lE-0gFWlOxhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/train (1).csv\")\n",
        "\n",
        "# Drop Id\n",
        "df.drop(columns=['Id'], inplace=True)"
      ],
      "metadata": {
        "id": "oJBIsnD-OvPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill NaNs in categorical columns**"
      ],
      "metadata": {
        "id": "kN3V-VX1QoZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include='number').columns\n",
        "for col in num_cols:\n",
        "    df[col].fillna(df[col].median(), inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4ZbloyYQtT8",
        "outputId": "da94d89d-add9-4818-f330-127f8f0d348e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1317444104.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical columns :mode**"
      ],
      "metadata": {
        "id": "42pr7V5MUMCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical columns ‚Üí mode\n",
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "for col in cat_cols:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apscGSGtUJ4a",
        "outputId": "f2e9f52b-6f50-4727-a60a-c1550d16c275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2981746983.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 2: Outlier handling**"
      ],
      "metadata": {
        "id": "EMEjJppOO4mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include='number').columns\n",
        "num_cols = num_cols.drop('SalePrice')\n",
        "\n",
        "for col in num_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "\n",
        "    df[col] = df[col].clip(lower, upper)"
      ],
      "metadata": {
        "id": "InsuuLTsO4C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 3: Special handling for LotArea**"
      ],
      "metadata": {
        "id": "jiT67q5jPGe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lower = df['LotArea'].quantile(0.01)\n",
        "upper = df['LotArea'].quantile(0.99)\n",
        "\n",
        "df['LotArea'] = df['LotArea'].clip(lower, upper)\n",
        "df['LotArea'] = np.log1p(df['LotArea'])"
      ],
      "metadata": {
        "id": "EuJtMBpnO8ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 4: Target transform**"
      ],
      "metadata": {
        "id": "R5Sa9nS9PM69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('SalePrice', axis=1)\n",
        "y = np.log1p(df['SalePrice'])"
      ],
      "metadata": {
        "id": "vALzaruQPLGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 5: Drop high-cardinality categorical columns (LR decision)**"
      ],
      "metadata": {
        "id": "PZrrUcx-PSaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obj_cols = X.select_dtypes(include='object')\n",
        "high_card_cols = obj_cols.columns[obj_cols.nunique() > 10]\n",
        "\n",
        "X = X.drop(columns=high_card_cols)"
      ],
      "metadata": {
        "id": "mRUEZTjxPP6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 6: Identify categorical columns for OHE**"
      ],
      "metadata": {
        "id": "bQQjzH_gPYAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ohe_cols = X.select_dtypes(include='object').columns"
      ],
      "metadata": {
        "id": "_W9z50m6PVwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 7: Train-test split**"
      ],
      "metadata": {
        "id": "Y8IFMsQSPhWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "WePp9s5WPdZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 8: Scaling + One-Hot Encoding**"
      ],
      "metadata": {
        "id": "CDjLRUYPPnl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "num_cols = X_train.select_dtypes(include='number').columns\n",
        "\n",
        "num_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        ('scaler', StandardScaler())\n",
        "    ]\n",
        ")\n",
        "\n",
        "cat_pipeline = OneHotEncoder(\n",
        "    drop='first',\n",
        "    handle_unknown='ignore',\n",
        "    sparse_output=False\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_pipeline, num_cols),\n",
        "        ('cat', cat_pipeline, ohe_cols)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "uG3CWsHyPlBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 9: Apply preprocessing**"
      ],
      "metadata": {
        "id": "ImzhwSRCP0PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_final = preprocessor.fit_transform(X_train)\n",
        "X_test_final  = preprocessor.transform(X_test)\n",
        "\n",
        "print(X_train_final.shape)\n",
        "print(X_test_final.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1mmW5iRPuB_",
        "outputId": "e2a71120-f398-494e-bcd8-8816ded29766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1168, 189)\n",
            "(292, 189)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [13, 26] during transform. These unknown categories will be encoded as all zeros\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 10: Train Linear Regression**"
      ],
      "metadata": {
        "id": "9uBqMosuP6Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_final, y_train)\n",
        "\n",
        "y_train_pred = lr.predict(X_train_final)\n",
        "y_test_pred  = lr.predict(X_test_final)\n",
        "\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "rmse_test  = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test  = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train RMSE (log): {rmse_train:.4f}\")\n",
        "print(f\"Test RMSE  (log): {rmse_test:.4f}\")\n",
        "print(f\"Train R¬≤: {r2_train:.4f}\")\n",
        "print(f\"Test  R¬≤: {r2_test:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6et62m0GP3E2",
        "outputId": "dff0debc-488b-4652-a782-d53720324309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE (log): 0.0976\n",
            "Test RMSE  (log): 0.1527\n",
            "Train R¬≤: 0.9375\n",
            "Test  R¬≤: 0.8751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LlzGFQvMTZHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "House Price Prediction using Linear Regression\n",
        "üìå Project Overview\n",
        "\n",
        "This project focuses on predicting house prices using Linear Regression.\n",
        "The main goal was to understand the complete end-to-end machine learning workflow, starting from raw data analysis (EDA) to building and evaluating a regression model.\n",
        "\n",
        "Instead of jumping directly to advanced models, I intentionally built a strong baseline model by carefully handling data quality issues like missing values, outliers, skewness, and categorical variables.\n",
        "\n",
        "üìÇ Dataset Information\n",
        "\n",
        "Dataset Name: House Prices ‚Äì Advanced Regression Techniques\n",
        "\n",
        "Source: Kaggle\n",
        "\n",
        "Link: https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques\n",
        "\n",
        "Dataset Size:\n",
        "\n",
        "Rows: 1460\n",
        "\n",
        "Columns: 81 (including target)\n",
        "\n",
        "The target variable is:\n",
        "\n",
        "SalePrice ‚Üí Price at which the house was sold\n",
        "\n",
        "üõ†Ô∏è Tools & Libraries Used\n",
        "\n",
        "Python\n",
        "\n",
        "NumPy\n",
        "\n",
        "Pandas\n",
        "\n",
        "Scikit-learn\n",
        "\n",
        "üîé Step-by-Step Workflow\n",
        "1Ô∏è‚É£ Data Loading & Basic Cleaning\n",
        "\n",
        "Loaded the dataset using Pandas\n",
        "\n",
        "Dropped the Id column (not useful for prediction)\n",
        "\n",
        "2Ô∏è‚É£ Handling Missing Values (Manual)\n",
        "\n",
        "To keep things simple and transparent:\n",
        "\n",
        "Numerical columns ‚Üí filled missing values using median\n",
        "\n",
        "Categorical columns ‚Üí filled missing values using mode\n",
        "\n",
        "This removed all NaN values from the dataset.\n",
        "\n",
        "3Ô∏è‚É£ Outlier Handling\n",
        "\n",
        "Used the IQR (Interquartile Range) method to cap outliers in numerical features\n",
        "\n",
        "Instead of removing rows, values were clipped to reduce extreme influence\n",
        "\n",
        "Special handling:\n",
        "\n",
        "LotArea had heavy right skew\n",
        "\n",
        "Applied 1st‚Äì99th percentile clipping\n",
        "\n",
        "Followed by log transformation\n",
        "\n",
        "4Ô∏è‚É£ Target Variable Transformation\n",
        "\n",
        "SalePrice was heavily right-skewed\n",
        "\n",
        "Applied log1p(SalePrice) to:\n",
        "\n",
        "Reduce skewness\n",
        "\n",
        "Improve linear regression performance\n",
        "\n",
        "Stabilize variance\n",
        "\n",
        "5Ô∏è‚É£ Handling Categorical Features\n",
        "\n",
        "Identified categorical columns based on data type\n",
        "\n",
        "High-cardinality categorical columns (more than 10 unique values) were dropped for Linear Regression to:\n",
        "\n",
        "Avoid feature explosion\n",
        "\n",
        "Reduce multicollinearity\n",
        "\n",
        "Keep the model interpretable\n",
        "\n",
        "(These columns can be reintroduced later for Ridge, Lasso, or tree-based models.)\n",
        "\n",
        "6Ô∏è‚É£ Feature Encoding\n",
        "\n",
        "Applied One-Hot Encoding to remaining categorical columns\n",
        "\n",
        "Used drop='first' to avoid the dummy variable trap\n",
        "\n",
        "Handled unseen categories safely\n",
        "\n",
        "7Ô∏è‚É£ Feature Scaling\n",
        "\n",
        "Numerical features were scaled using StandardScaler\n",
        "\n",
        "Scaling was applied only to numeric columns (not categorical dummies)\n",
        "\n",
        "8Ô∏è‚É£ Train-Test Split\n",
        "\n",
        "Split the data into:\n",
        "\n",
        "80% Training\n",
        "\n",
        "20% Testing\n",
        "\n",
        "Used a fixed random_state for reproducibility\n",
        "\n",
        "9Ô∏è‚É£ Model Building\n",
        "\n",
        "Built a Linear Regression model\n",
        "\n",
        "Trained the model using the processed training data\n",
        "\n",
        "üîü Model Evaluation\n",
        "Evaluation Metrics Used:\n",
        "\n",
        "R¬≤ Score\n",
        "\n",
        "RMSE (Root Mean Squared Error)\n",
        "\n",
        "Final Results:\n",
        "Train R¬≤ : 0.9375\n",
        "Test  R¬≤ : 0.8751\n",
        "\n",
        "Train RMSE (log): 0.0976\n",
        "Test  RMSE (log) : 0.1527\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "The model shows strong performance on unseen data\n",
        "\n",
        "Slight train‚Äìtest gap indicates mild overfitting, which is expected\n",
        "\n",
        "Overall, this is a solid baseline Linear Regression model"
      ],
      "metadata": {
        "id": "lajEc8RPaK9W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sifw3JxkaL5V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}